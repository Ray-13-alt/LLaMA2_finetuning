Personal Project: Fine-Tuning Llama-2 Language Model

Developed a fine-tuned version of the Llama-2 language model using Hugging Faceâ€™s Transformers and PEFT libraries.
Implemented QLoRA for efficient training, enabling 4-bit precision and low-rank adaptation techniques.
Designed a text generation pipeline that produces coherent and contextually relevant outputs.
Technologies: Python, PyTorch, Transformers, Datasets, PEFT.
